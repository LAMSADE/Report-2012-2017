%\begin{description}
%\item[People:]~\newline
%\begin{itemize}
%\item Jamal Atif (pole 3), hired as Professor in September 2014, bringing new competences in machine learning, specifically regarding representation changes and regularization.
%\item Florian Yger (pole 3), hired as Assistant Professor in September 2015, bringing new competences in representation learning and Riemannian-based approaches
%\item Benjamin Negrevergne (pole 3), hired as Assistant Professor in September 2016, bringing competences in Unsupervised learning/Data Mining and distributed algorithms
%\item Tristan Cazenave (pole 1)
%\item Rida Laraki (pole 1)
%\item Dario Colazzo (pole 3)
%\end{itemize}
%\end{description}


The identification, collection, and analysis of information related to activities of organisations is vital for effectively supporting their decision making processes. A wide part of such information can today be effectively measured so that the resulting data can be stored and transformed in order to enable automatic data querying and  analysis to aid decision makers. On the one hand, this has triggered strong research interest on techniques able to collect,  manage and analyse big data collections both in a flexible and in a robust way.  On the other hand, this data  deluge, together with  the novel resulting analytics possibilities,  have reinforced and re-oriented the need of  investigation efforts about problems related to how to interpret and make actionable data analysis results, by  involving  and analysing knowledge about facts and phenomena that can not be measured currently, and that depend on the particular (social, economical, ...) context in which the organisation activities are carried out.  

The research activities of the Data Science team situate in this twofold context, and are carried out within four projects, respectively  focusing on large scale data management, machine learning, Web services, and policy analytics. In each of these projects,  members of the Data Science team have obtained results published in top-level (A/A*) conferences  and  journals \cite{Colazzo2014RDF-629026,Camacho-Rodriguez2014PAXQuery:-1007886,DBLP:journals/tkde/Camacho-Rodriguez15,DBLP:conf/cikm/Camacho-Rodriguez16,Abu-Khzam2015On-1017005,Gamez2015SPL-TQSSS:-1298429, DBLP:conf/icsoc/GabrelMM14,GMMM17,DBLP:conf/icsoc/2015,DBLP:conf/icsoc/2014w,Bojarski2017Structured-1259771,AngaritaArocha2016Modeling-1159056,AngaritaArocha2012FaCETa:-619549,AngaritaArocha2015Dynamic-1061562,Mouhoub2014A-1061556,Mouhoub2015LIDSEARCH:-1061527,DBLP:conf/eScience/CarvalhoBM16,DBLP:conf/ssdbm/RiosPFB16,DBLP:conf/ssdbm/BelhajjameB16,DBLP:journals/dpd/BelhajjamePHF15,DBLP:journals/ws/Belhajjame0GGHP15,DBLP:journals/fgcs/GarijoABCGG14,DBLP:journals/tsc/BelhajjameEP14,DBLP:conf/edbt/Belhajjame14,Bacall2013The-904520,Belhajjame2013Incrementally-904545,Missier2013The-1007766}.  It is worth stressing that the scientific community to which the team belongs is highly competitive and includes a large number of  prestigious research research groups and companies in all over the  world. In this context, members of the team  enjoy high international visibility  as shown by their  participation to program committees of prestigious venues, such as PODS, SIGMOD, VLDB, ICSOC, SSDBM, EDBT,  NIPS, AISTAT, IJCAI, .... Several members of the  team have also been deeply involved  in the organisation of the 2015 edition of ICSOC conference. Research results have been obtained in the context of several collaborations with both national and international universities, as well as  with  national and international companies like  SNCF, Adway, Hortonworks, IBM, Google. 

\smallskip
The quasi-totality  of the team is  deeply involved in teaching and management activities in crucial domains related with data science,  like algorithms, programming, large scale data management, data mining and machine learning. Particular effort of the team has been dedicated in the last three years to  re-orientation activities at MIDO in order to offer students new Big Data and Data Science courses together with the needed hardware support.  These efforts have revealed to be particularly successful.

\smallskip
The team looks forward  to integrating  new CNRS researchers in the near future, as well as  CNRS research engineers, as currently only one CNRS researcher is part of the team, and the team can not count on the activities of engineers, who would play a crucial role in all those research lines demanding substantial efforts in the implementation of complex techniques devised by the team. 


\medskip
Reports and perspectives about the research projects are described  in the sequel. 


\subsection{MADAX: Massive Data Management, Analysis and Exploration.}

The MADAX project focuses on problems related to i) static analysis for safe and efficient management of massive semistructured data, ii) big data integration, and iii) experiment reproducibility. 

Concerning the first line of research, efforts have been concentrated on expressive and efficient analysis of massive tree-shaped and  RDF  datasets, by relying in particular on MapReduce-like programming paradigms like PACT and Pig Latin \cite{DBLP:conf/cikm/Camacho-Rodriguez16, DBLP:journals/tkde/Camacho-Rodriguez15, DBLP:conf/sigmod/Camacho-RodriguezCM14}. These systems aim at providing  the data analyst with high-level languages to specify complex data flow programs, that are then opportunely optimised  and compiled to low-level MapReduce-like data flows, that are executed on cluster of computers. The main technical challenge in this context is  to bridge the gap between high expressivity of user languages and basic MapReduce-like algebras. So it is has been essential to specify the approaches in a rigorous formal way and to conduct extensive experimental analysis.      In the context of RDF data sets, we have devised and implemented techniques for OLAP-like analytics of RDF data-warehouses by relying on a new notion of analytical schema \cite{Colazzo2014RDF-629026}. The main distinctive feature of this approach was the presence of techniques enabling the specification of global queries on several databases without the need of ETL preprocessing in order to build a unique data warehouse.  Recent research efforts focus on the development of static analysis techniques for type-checking complex graph queries \cite{DBLP:conf/dbpl/ColazzoS15}. Before this work no type-checking techniques existed for graph queries, and this work has been the first to introduce and adopt  a new notion of schema for data graphs taking into account a wide class of properties of graphs, and enabling rich forms of query type analysis. 


Data integration has been an active area of research for three decades. Yet, it is proving to be a costly operation, especially in the era of Big Data when the number of sources that need to be processed and combined to bring out value, seems to be constantly on the rise. To reduce the cost of building data integration systems, we have investigated several techniques that solicit feedback from end-users for building and improving the quality of a data integration system in a pay-as-you-go manner \cite{DBLP:conf/ssdbm/RiosPFB16}.  Other explored research lines include the  problem of clustering data integration users based on their expectations \cite{DBLP:journals/dpd/BelhajjamePHF15}, and the use of  map-reduce paradigm for parallelizing the data exchange problem \cite{DBLP:conf/ssdbm/BelhajjameB16}, which is tightly related to data integration. More recently, we have started investigating data privacy issues that arises in such contexts \cite{DBLP:journals/computer/BarhamgiBYBN16}.

Reproducibility is an issue that is increasingly gaining importance due to the fact that many of the research solutions that are out there cannot be repeated or replicated. In this regards, we have investigated several techniques for improving the reproducibility of computational experiments by utilizing provenance information together with semantic annotations \cite{DBLP:journals/ws/Belhajjame0GGHP15,DBLP:conf/eScience/CarvalhoBM16, DBLP:journals/biomedsem/HettneD0WBSMTCVGRCKSHBGR14}. Other research efforts have concerned  summarization techniques for abstracting such experiments \cite{DBLP:conf/ipaw/AlperBGK14}, as well as techniques for improving the reproducibility of scripts written by scientists by making them full-fledged research objects \cite{DBLP:conf/eScience/CarvalhoBM16}.

The MADAX project is particularly involved in transferring knowledge from the research field to Big Data training programs at LAMSADE and MIDO, and have recently set up a preliminary web page presenting these activities.\footnote{\url{https://www.lamsade.dauphine.fr/pole3/}}


%\eat{
%
%\subsubsection{Perspectives}
%
%Future perspectives of MADAX include efficient techniques for summarising tree-shaped data (e.g. JSON), which are widely used toady in data lakes that are at the basis of complex analytics (SQL, data mining, machine learning). Preliminary results have been presented this year at EDBT \cite{} and seem very promising promising. We also  plans to  continue  hour investigation  about  schema and query languages for  large scale data graph processing, continuing research lines depicted in \cite{}.  Other future directions concern  the  investigation of data integration problems in particular in data lakes, and the reproducibility of data-intensive in-silico experiments, as well as  RDF data management problems, namely RDF saturation, minimisation and provenance-enabled query evaluation.
%
%
%
%
%
%
%---
%Future perspectives of the team include efficient techniques for summarising tree-shaped data (e.g. JSON), which are widely used toady in data lakes that are at the basis of complex analytics (SQL, data mining, machine learning). Preliminary results have been presented this year at EDBT and seem promising. We have shown how it is possible to summarise schema information from massive JSON collections by relying on merge mechanisms that can be implemented on Spark for the parallel execution on cluster of computers. In the future we aim at extending our formal systems with counting informations and techniques able to infer information about structural correlation in the data. These mechanisms are crucial for effective data exploration, a crucial task in data science and that precedes the development of applications for preparing data for analytics and  machine learning tasks. 
%We aim at extending those techniques to data graphs, which are widely used today in crucial scenarios as those related to cyber security, social network, recommendation systems. 
%
%Still in in the context os static analysis,  we aim at devising new techniques  for the  efficient validation of semi-structured data against rich form of schemas, for which efficient approaches do not currently exist. We aim at including both tree- and graph-shaped data in the study, and on aiming on streaming techniques that are typical of existing frameworks for big data real time applications. 
%
%In the context of massive knowledge databases, we aim at devising techniques for the efficient saturation of RDF graphs in the presence of rich OWL ontologies. Again, to face the presence of massive data, we aim at devising techniques that can be implemented on top of very recent frameworks based on the \emph{Think as a Subgraph}  computational model, which are opposed to the traditional \emph{Think as a vertex} models promoted by big actors like Facebook and Google, and widely used today for big graph processing. We expect that these new models can entail optimisations that were not possible previously. Still in this context, we plan to investigate techniques for RDF distilling operations, consisting of erasing redundant, implicit information, that could be obtained by means of ontologies. Of course, the main motivation is to optimise storage space, given that techniques exists which are able to avoid saturation in the presence of ontologies for RDF querying.  
%
%}%end eat



\subsection{Machine Learning}The ML scientific project, bringing together researchers from the ``Data science'' and ``Decision Aid'' poles of LAMSADE, addresses  open issues raised at the front edge of Data sciences and Decision making. Its long-term overall goal is to  construct principled models allowing to understand, predict and control artificial agents evolving in  possibly highly dynamic environments. To achieve this goal, the main work-plan of the project members has been conducted through two lines of research: (i) invariance design and representation learning, and (ii) learning for optimal decision making under uncertainty. In addition, recent research activity has aimed at  large scale topology based selection by means of hierarchical sampling.

%To achieve this goal, the work-plan of the project members has been conducted through two lines of research: (i) invariance design and representation learning, and (ii) learning for optimal decision making under uncertainty.

%\subsection{Salient achievements}
\subsubsection{Invariance design and representation learning}
One of the most challenging and still open problems in Machine Learning is to extract meaningful patterns from few or unlabeled high dimensional data, possibly scarce and exhibiting non-stationary regimes. Such data are numerous in the real world (e.g., brainwaves signals or financial data). To approach this problem our claim is to rely first on our prior knowledge about the invariances and regularities of the observed phenomenon and encode it in the exploration process, and when such a knowledge is not available, learn from the data a change of representation, i.e. a mapping from the initial space to a feature space well suited to the final decision phase. As such, our work falls within the emerging topic of representation learning. More precisely, we studied in~\cite{Bloch2016Defining-1222794} transportation metrics, i.e. probability distances exhibiting invariances over the data space, and proposed geodesic extensions  by establishing a link between the Optimal Transport and Mathematical Morphology theories. These metrics are under study in order to be embedded in unsupervised learning algorithms.   In~\cite{Bojarski2017Structured-1259771}, the change of representation is performed through structured random projections. We propose in particular  an efficient computational framework for speeding up several machine learning algorithms with almost no loss of accuracy
comparing to its unstructured counterpart and propose a general theoretical
principle allowing to provide the first theoretical guarantees of several approaches in the literature. In~\cite{Isaac2017Multi-dimensional-1222778}, the mapping from the raw data (multidimensional brainwave signals) to the feature space is performed through learning a regularized over complete basis of multidimensional signals. Besides learning this new feature space in an unsupervised way, prior knowledge about the regularities of the brainwaves signals are encoded through new regularization terms in order to enforce a sparse decomposition preserving the spatio-temporal structure of the signal.  An optimization algorithm based on the split
Bregman approach is also proposed to handle the associated optimization problem,
and  its  convergence  is  analyzed. In~\cite{Horev2016Geometry-aware-1241260,Yamane2016Multitask-1241267} we studied how dimensionality reduction approaches can be compliant to the intrinsic geometry of the data space. This led to the development of geometry-aware Principal Component Analysis algorithms on a Riemannian manifold. We have also established a systematic review of other Riemannian approaches in the analysis of high-dimensional multivariate brainwave signals for brain-computer interfaces in~\cite{Yger2017Riemannian-1241283}.


\subsubsection{Learning for optimal decision making under uncertainty}

At the very core of Artificial Intelligence is the design of self-adapting agents able to explore, interact with, and control their environments. From the ML perspective this falls within reinforcement learning or online learning approaches. In the context of Computer Games, we have continued our seminal works on Monte Carlo Tree Search (MCTS) and proposed improvements to the architecture of the deep neural networks of AlphaGo ~\cite{cazenave2017residual}: the improved networks make use of residual layers which enable to train deeper networks and improves significantly the precision. We have also proposed online learning of playout policies~\cite{Cazenave2016Playout-1222820,Cazenave2015Generalized-1222829}: the principle is to use Gibbs sampling with weights associated to the different possible moves and to reinforce the moves that led to a win in playouts and decrease the probability of playing the other moves. It led to significantly stronger MCTS program for many games. In~\cite{FLP2016}, we studied the generalization of regret minimization to the vectorial or multi-criteria setup called Blackwell approachability. We show that in this setting, unlike in the standard online learning literature, the necessary or sufficient conditions for the anytime version of this problem are drastically different than those for the fixed horizon. In~\cite{Linguet2015Estimating-1260037,Linguet2016A-1222799} we have modeled the solar surface irradiance (SSI) incident on the Earth surface as an online learning problem and proposed original MCMC particle filter approaches that combine satellite images and in situ data for space-time-referenced SSI.

\subsubsection{Large scale learning from active sampling}

Traditional data analytic techniques (such as statistical or evolutionary learning) are sometimes powerless faced with the current size explosion of data collections.  In collaboration with Amel Borgi (LIPAH, University of Tunis El Manar), we are interested in large scale evolutionary algorithms to deal with massive data classification problems. As part of a PhD student work, we have recently proposed an extension of the evolutionary algorithms in order to optimize their performance of learning from active sampling in  large  data sets \cite{Hmida2016Sampling-1298248,Hmida2016Hierarchical-1241346}. Preliminary results to learn from the Higgs Decay Dataset (containing 80 million collision events coming from the field of high-energy physics) show that our proposed method is able to deal with a benchmark data set of 11 millions events.

%\subsubsection{Evolutionary learning for the search of big data }

%The amount of available data for data mining and knowledge discovery continue to grow very fast with the era of Big Data. Traditional data analytic techniques (such as statistical or evolutionary learning) are sometimes powerless faced with the mass of data to exploit risking of inducing over-training. In collaboration with Amel BORGI (LIPAH, u. of Tunis El Manar), we are interested in big data analytics via evolutionary algorithms, particularly in Genetic Programming (GP). GP techniques have shown to be a very promising solution to deal with the large data classification scenario. Nevertheless, these algorithms suffer from an increased computational cost induced mainly by the evaluation step. As part of a PhD student work, we have proposed, an extension of the GP in order to optimize their performance of learning from active sampling of large volume data\cite{Hmida2016Sampling-1298248,Hmida2016Hierarchical-1241346}. Satisfactory preliminary results to learn from the Higgs Decay Dataset, a dataset containing 80 million collision events coming from the field of high-energy physics, show that our proposed method was able to deal with a benchmark data set of 11 millions events.


%\eat{
%
%\subsubsection{Perspectives}
%
%Note: the project perspectives have partly been inspired by, and have also inspired the recent french report on AI \#FranceIA.
%
%\fbox{Attention chantier}
%
%
%A long-term fascinating goal in computer sciences, since its early ages, is to design artificial agents able to learn and to self-adapt to their environments. The (unexpected) recent success of machine learning techniques (e.g. deep learning)  in several domains ranging from Computer Go, machine translation to autonomous vehicles, makes this goal somehow "at our fingertips". Admittedly, Machine Learning (ML) has changed the way decision making is handled and is considered now an unavoidable step in any data processing pipeline. However, recent advances have been achieved with models that consume very massive amount of annotated data, and the inferred decisions are hard to explain. Along with privacy issues, this lack of explainability is more likely to hinder the acceptability of ML and Artificial Intelligence techniques. 
%
%The perspectives of the ML@LAMSADE project are thought to tackle these new disruptive subjects. More precisely we will continue our investigation on learning from few or unlabeled high-dimensional data through representation learning and invariance design.  A new effort will be devoted to massive graph-structured data and to the design of efficient and scalable distributed algorithms. Current investigations in this topic are concerning the design of a new theory of dictionary learning of graph data (CNRS JCJC project), and the development of clustering of sketched massive graphs (work with Google Brain and CEA is about to be published). The quest for principled and computationally efficient geometry-aware unsupervised learning algorithms will also be pursued through the study of Riemannian manifolds and their application to the analysis of brainwave signals (EEG data). An ANR project is under review concerning this topic. Matrix factorization techniques taking into account side information will also be studied in the context of recommendation systems. The second research direction follows our investigations on learning for   optimal sequential decision making, with a determined effort to establish connection with representation learning. Deep reinforcement learning approaches, at the crossroad between reinforcement learning and deep representation learning will be studied in the context of computer Go. Multi-armed bandit approaches and learning in repeated games will also be studied in the context of recommendation systems.  
%A new - high risk high gain - research direction will be devoted to deontic and explainable machine learning techniques. Privacy-preserving models will be at the core of our work on graph sketching and clustering. Within the context of recommendation systems, substantial efforts will be devoted to the design of new inference models (through e.g. game theoretic approaches) taking into the opinion polarization and the "echo chamber"  phenomenon. Finally, the hard problem of deriving explainable decision models will necessitate imagining new synergies between symbolic and numeric approaches...
%
%\textbf{Perspectives on Evolutionary learning for the search of big data}
%
%We would like to continue our work on two levels of extensions:
%The first level aims to reduce the complexity of the problem by using sets of learning, where information (data or attributes) are judged among different learners and the "individual" opinions are then combined to reach a final decision.
%The second one aims the reduction of costs of calculations by introducing intensive parallel calculations and data distribution taking into account the volume and variety of data. 
%
%}%end eat


\subsection{Web services}

The Web Services research group aims at developing fundamental concepts and techniques for services computing and business processes management.
The main research directions investigated by our group are the following:
\begin{itemize}
\item Service discovery and composition taking into account non-functional properties (transactional properties, trust and other QoS properties).
\item    Workflow modeling, matching and discovery.
\item    Process mining and process analytics.
\end{itemize}


\textbf{Automatic QoS-aware service composition and execution}
A part of the service project is transversal between ``Combinatorial optimization, algorithms" and ``Data Sciences" research areas, and particularly between Virginie Gabrel, C{\'e}cile Murat and Maude Manouvrier. We have been tackling the Automatic QoS-aware service composition problem, which is a combinatorial optimization problem. Two decision contexts are usually considered to structure the composition problem: in the first one, a workflow is used to represent the composite service as a combination of functionalities, and, in the second one, a graph represents the input/output dependencies between services. In both contexts, the theoretical complexity of different versions of the composition problem based on Quality of Service (QoS) have been studied and original models and exact algorithms (based on linear programming and graph theory) have been proposed. These results have been published in international journals and conferences: in Discrete Applied Mathematics \cite{DBLP:journals/dam/GabrelMM15}, for the first context, and in ICSOC conference \cite{DBLP:conf/icsoc/GabrelMM14} and Future Generation Computer Systems, for the second one \cite{GMMM17}.

%Our work also deals with service execution. 
Concerning service execution, as part of a PhD student work, we have defined a model to support self-healing (i.e non intrusive dynamic fault-tolerant) composite service executions while maintaining the QoS requirements, even in presence of failures (\cite{AngaritaArocha2016Modeling-1159056,AngaritaArocha2012FaCETa:-619549,AngaritaArocha2015Dynamic-1061562}). 

%\textbf{Contribution Joyce}
\textbf{Service discovery}
As part of a PhD student work and in the context of CAIR ANR project, we proposed a framework for searching semantic data and services using SPARQL (\cite{Mouhoub2014A-1061556,Mouhoub2015LIDSEARCH:-1061527}).
As part of a collaboration with ``Combinatorial Optimization, Algorithms" pole, we studied and proved the exact complexity of the service selection problem by taking into account QoS criteria for single and multi-criteria instances \cite{Abu-Khzam2015On-1017005}. As part of a thesis co-supervised with ``Decision Aid" pole, we have enriched the processes of discovery and selection of services by considering both the social dimension of the providers and the experience feedback of the previous compositions \cite{Louati2015A-1250421, Louati2014A-990319, Louati2014A-1298436}. We have established a trust measure in providers and their services evaluated on three components: sociability, expertise and recommendation \cite{Louati2014Towards-1307413}.
We have also been interested in coalitions formation based on trust for service composition \cite{Louati2015Trust-Based-1269604}.
In order to guarantee the reliable execution of a composition, in collaboration with the University of M\'alaga we have proposed an original approach based on product lines for the problem of service selection taking into account their transactional properties and their QoS values \cite{Gamez2015SPL-TQSSS:-1298429}.

\textbf{Workflow modeling and mining}
We have investigated means for assisting users in the specification of workflows by reusing workflow fragments. Specifically, we devised a technique that utilizes existing sub-graph mining techniques, namely SUBDUE, to identify workflow fragments that are likely to meet the needs of a workflow designer \cite{DBLP:conf/cost/HarmassiGB15}. We have also investigated techniques that can be utilized for the verification of semantic annotations of web services, which are used to implement the steps (tasks) in the workflow specification. The semantic annotations describe the domain of the input and output parameters of web services. For their verification, we used and adapted software functional testing \cite{DBLP:journals/tsc/BelhajjameEP14}. We have also showed how data examples can be utilized for annotating the operational semantics of scientific modules, which are operations that are utilized in scientific experiments \cite{DBLP:conf/edbt/Belhajjame14}.  
A technique for mining unstructured, flexible, knowledge-intensive processes has been proposed in\cite{Delias2015Discovering-1223048}.  Based on our experience on process mining and matching we participated in writing a monograph \cite{DBLP:books/sp/BeheshtiBSGMBGR16} that surveyed  approaches and tools for process analytics.


\textbf{Process matching} 
In the context of ANR AOC project we studied the problem of workflow matching and discovery. In collaboration with our partners experts in graph theory we proposed a spectral graph approach for process model matchmaking  (\cite{DBLP:conf/IEEEscc/BelhoulHGGKB13}). In order to allow to retrieve in a repository of process models the one the most similar to the query, we proposed indexes based on semantic annotations inputs and outputs of activities and their relationship in\cite{Gater2012Indexing-624941}. User preferences concerning QoS properties have been modeled using fuzzy set theory and taken into account in the discovery process (\cite{Bouzeghoub2012Integration-624705,Grigori2012Adding-619546,Bouzeghoub2012A-619531}.


%\eat{
%
%\textbf{Perspectives}
%
%We would like to continue our research work on two axes, on the one hand, we would like to continue the search for robust solutions in the web services composition and its execution control; on the other hand we would like to study the application of these solutions in specific cases as the connected objects for the smart buildings.
%
%In our research, we execute a service selection process (by identifying the components of a composite service that satisfies a query), and then execute the resulting composite service, using the self-healing approach. The selection is done with an optimistic assumption: characteristics and behaviors of services seldom change. Failures or changes in service characteristics (e.g., QoS degradation) are considered during the execution. However, in order to prevent undesirable impacts, notably the degradation of the QoS performances of the composition or the component failures, we have to take into account possible changes in the workflow or in the  graph, during the optimization process. Based on the recovery strategies we offer in \cite{AngaritaArocha2016Modeling-1159056, AngaritaArocha2015Dynamic-1061562}, we would like to provide new models that offer new service compositions that integrate, as soon as they are defined, the envisaged recovery strategies. The challenge is to investigate a novel approach based on robust
%optimization, never used for service composition to our knowledge.
%
%In applications of automatic control, such as intelligent buildings systems, thousands of devices or sensors are connected to collect and analyze data in real time and react according to certain anomalies or conditions that such applications are supposed to control. With potentially large number of remote sensors it may be difficult to send all these data to one central server to be analyzed and still to expect timely systems responses. A possible solution could be to attach Internet data servers to sensors in order to collect and analyze data, and make local control decisions. However, due to the unreliable and dynamic nature of sensors and their environment, their quality could change over time resulting in some control violations and penalties for the smart applications. Based on our results obtained in~\cite{AngaritaArocha2016Modeling-1159056} we would like to propose new solutions for smart buildings based on dynamic web service composition. 
%
%In the field on process mining and process analytics we will address new challenges related to size and heterogeneity of event logs. We are working on extracting process related information from unstructured data (email logs) and proposing real-time process analysis techniques in order to predict and improve process execution.
%
%As well as the above topics, we are investigating techniques for enforcing and promoting the reproducibility of research results. We will also be investigating the problem of data privacy \cite{DBLP:journals/computer/BarhamgiBYBN16}, in particular when manipulating datasets coming from different sources. 
%
%-----------
%\textbf{Web Services Perspectives - Short}
%
%%Our goal is to propose intelligent and robust solutions for process and web services composition execution. We will investigate mainly two research directions: self-healing execution and process and services analytics.
%
%%In the first direction, we will continue our research work on web services composition and execution. In our past work, we proposed selection strategies that assume that characteristics and behaviors of services seldom change. In order to prevent undesirable impacts, notably the degradation of the QoS performances of the composition or the component failures, the challenge is to investigate a novel approach based on robust optimization, never used for service composition to our knowledge. We would like to study the application of these solutions in specific cases as the connected objects for the smart buildings. Based on our results obtained in~\cite{AngaritaArocha2016Modeling-1159056}, we will propose new solutions for smart buildings based on dynamic and robust web service composition.
%
%%In the second research direction, in the field on process mining and process analytics we will address new challenges related to the size, heterogeneity and velocity of event logs. 
%%We are working on extracting process related information from unstructured data (email logs, …) as a first step towards the analysis of undocumented business processes. 
%%Techniques like text clustering, natural language processing, process mining are required. We aim also at proposing real-time process and services analysis techniques in order to predict process behavior and improve its execution.
%
%}% end  eat

\subsection{Perspectives}

Future perspectives of MADAX include efficient techniques for summarising tree-shaped data (e.g. JSON), which are widely used today in data lakes that are at the basis of complex analytics (SQL, data mining, machine learning). Preliminary results have been presented this year at EDBT \cite{DBLP:conf/edbt/BaaziziLCGS17} and seem very promising. We also  plan to  continue  hour investigation  about  schema and query languages for  large scale data graph processing, continuing research lines initiated in  \cite{DBLP:conf/dbpl/ColazzoS15}.  Other future directions concern  the  investigation of data integration problems in data lakes, and the reproducibility of data-intensive in-silico experiments, as well as  RDF data management problems, namely RDF saturation, minimization and provenance-enabled query evaluation.


% Concerning the Machine Learning project, its perspectives have partly been inspired by, and have also inspired the recent french report on AI \#FranceIA. A long-term fascinating goal in computer sciences, since its early ages, is to design artificial agents able to learn and to self-adapt to their environments. The (unexpected) recent success of machine learning techniques (e.g. deep learning)  in several domains ranging from Computer Go, machine translation to autonomous vehicles, gives the impression that this goal somehow "at our fingertips", but but there is still much to be done. Admittedly, Machine Learning (ML) has changed the way decision making is handled and is considered now an unavoidable step in any data processing pipeline. However, recent advances have been achieved with models that consume very massive amount of annotated data, and the inferred decisions are hard to explain. Along with privacy issues, this lack of explainability is more likely to hinder the acceptability of ML and Artificial Intelligence techniques. 

% The perspectives of the ML@LAMSADE project are thought to tackle these new disruptive subjects. More precisely we will continue our investigation on learning from few labeled or unlabeled high-dimensional data through representation learning and invariance design.  A new effort will be devoted to massive graph-structured data and to the design of efficient and scalable distributed algorithms. Current investigations in this topic are concerning the design of a new theory of dictionary learning of graph data (CNRS JCJC project), and the development of clustering of sketched massive graphs (work with Google Brain and CEA is about to be published). The quest for principled and computationally efficient geometry-aware unsupervised learning algorithms will also be pursued through the study of Riemannian manifolds and their application to the analysis of brainwave signals (EEG data). An ANR project is under review concerning this topic. Matrix factorization techniques taking into account side information will also be studied in the context of recommendation systems. The second research direction follows our investigations on learning for   optimal sequential decision making, with a determined effort to establish connection with representation learning. Deep reinforcement learning approaches, at the crossroad between reinforcement learning and deep representation learning will be studied in the context of computer Go. Multi-armed bandit approaches and learning in repeated games will also be studied in the context of recommendation systems.  
% A new - high risk high gain - research direction will be devoted to deontic and explainable machine learning techniques. Privacy-preserving models will be at the core of our work on graph sketching and clustering. Within the context of recommendation systems, substantial efforts will be devoted to the design of new inference models (through e.g. game theoretic approaches) taking into the opinion polarization and the "echo chamber"  phenomenon. Finally, the hard problem of deriving explainable decision models will necessitate imagining new synergies between symbolic and numeric approaches.

Concerning the Machine Learning project, its perspectives are thought to tackle these new disruptive subjects in ML and AI and their relations to decision making\footnote{These perspectives have partly been inspired by, and have also inspired the recent french report on AI \#FranceIA}. More precisely we will continue our investigation on learning from few labeled or unlabeled high-dimensional data through representation learning and invariance design.  A new effort will be devoted to learning from massive graph-structured data and to the design of efficient and scalable distributed algorithms. Current investigations in this topic are concerning the design of a new theory of dictionary learning of graph data (CNRS JCJC project), and the development of clustering of sketched massive graphs (within the context of a collaboration  with Google Brain and CEA-List). The quest for principled and computationally efficient geometry-aware unsupervised learning algorithms will also be pursued through the study of Riemannian manifolds and their application to the analysis of brainwave signals (EEG data). An ANR project is under review concerning this topic. Matrix factorization techniques taking into account side information will also be studied in the context of recommendation systems. The second research direction follows our investigations on learning for   optimal sequential decision making, with a determined effort to establish connection with representation learning. Deep reinforcement learning approaches, at the crossroad between reinforcement learning and deep representation learning will be studied in the context of computer Go. Multi-armed bandit approaches and learning in repeated games will also be studied in the context of recommendation systems.  
A new - high risk high gain - research direction will be devoted to deontic and explainable machine learning techniques. Privacy-preserving models will be at the core of our work on graph sketching and clustering. Within the context of recommendation systems, substantial efforts will be devoted to the design of new inference models (through e.g. game theoretic approaches) taking into the opinion polarization and the "echo chamber"  phenomenon. Finally, the hard problem of deriving explainable decision models will necessitate imagining new synergies between symbolic and numeric approaches.

Concerning Web Services, our  goal is to propose intelligent and robust solutions for process and web services composition execution. We will investigate mainly two research directions: self-healing execution and process and services analytics.

In the first direction, we will continue our research work on web services composition and execution. In our past work, we proposed selection strategies that assume that characteristics and behaviors of services seldom change. In order to prevent undesirable impacts, notably the degradation of the QoS performances of the composition or the component failures, the challenge is to investigate a novel approach based on robust optimization, never used for service composition to our knowledge. We plan  to study the application of these solutions in specific cases such as the connected objects for the smart buildings. Based on our results obtained in~\cite{AngaritaArocha2016Modeling-1159056}, we will propose new solutions for smart buildings based on dynamic and robust web service composition.

For what concerns services analytics, we will address new challenges related to the size, heterogeneity and velocity of event logs in the context of   process mining and process analytics, along the lines of current work on extracting process related information from unstructured data (email logs, …) as a first step towards the analysis of undocumented business processes. We aim also at proposing real-time process and services analysis techniques in order to predict process behavior and improve its execution.

